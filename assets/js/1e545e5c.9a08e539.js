"use strict";(self.webpackChunkblog_never_del=self.webpackChunkblog_never_del||[]).push([[882],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>k});var r=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var u=r.createContext({}),i=function(e){var n=r.useContext(u),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},c=function(e){var n=i(e.components);return r.createElement(u.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},d=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,u=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=i(t),k=o,m=d["".concat(u,".").concat(k)]||d[k]||p[k]||a;return t?r.createElement(m,s(s({ref:n},c),{},{components:t})):r.createElement(m,s({ref:n},c))}));function k(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,s=new Array(a);s[0]=d;var l={};for(var u in n)hasOwnProperty.call(n,u)&&(l[u]=n[u]);l.originalType=e,l.mdxType="string"==typeof e?e:o,s[1]=l;for(var i=2;i<a;i++)s[i]=t[i];return r.createElement.apply(null,s)}return r.createElement.apply(null,t)}d.displayName="MDXCreateElement"},5215:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>l,toc:()=>i});var r=t(7462),o=(t(7294),t(3905));const a={sidebar_position:2930,title:"\ud83c\udfaa\ud83c\udfaa\ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s"},s="K8s Build",l={unversionedId:"\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s",id:"\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s",title:"\ud83c\udfaa\ud83c\udfaa\ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s",description:"\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35 Basic info",source:"@site/docs/\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s.md",sourceDirName:".",slug:"/\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s",permalink:"/\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s",draft:!1,tags:[],version:"current",sidebarPosition:2930,frontMatter:{sidebar_position:2930,title:"\ud83c\udfaa\ud83c\udfaa\ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c\u279c K8s"},sidebar:"defaultSidebar",previous:{title:"\ud83c\udfaa\ud83c\udfaa\ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c K3s",permalink:"/\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f Cluster \u279c\u279c K3s"},next:{title:"\ud83c\udfaa\ud83c\udfaa\ud83d\udc2c\u2638\ufe0f\u2638\ufe0f0\ufe0f\u20e3 K8s \u279c Basic",permalink:"/\ud83c\udfaa\ud83c\udfaa \ud83d\udc2c\u2638\ufe0f\u2638\ufe0f-0\ufe0f\u20e3 K8s \u279c Basic.1"}},u={},i=[],c={toc:i};function p(e){let{components:n,...t}=e;return(0,o.kt)("wrapper",(0,r.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"k8s-build"},"K8s Build"),(0,o.kt)("p",null,"\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35 Basic info "),(0,o.kt)("p",null,"\ud83d\udd35 Why k8s "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"docker \n    >> docker compose    -- for simple use\n        >> swarm         -- no recommand\n            >> k8s       -- final \n\n\ndocker is everywhere.\nwhen you have lots docker. you need manager. \nk8s /k3s can help you.\n")),(0,o.kt)("p",null,"\ud83d\udd35 K8s / K3s "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"K3s is light weight.  \u279c less ram   (0.5G ram +)\nK8s is heavy weight.  \u279c much ram   \n\nk8s have cluster build tool:   kubeadm.\n\n\u25ce K8s Version \n    https://kubernetes.io/releases/\n        1.24+ \n")),(0,o.kt)("p",null,"\ud83d\udd35 minikube"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"for test only.    we need one.\nlearn on minikube. then try on k8s.\n")),(0,o.kt)("p",null,"\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35  K8s  Demo\n\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35  K8s  Demo\n\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35  K8s  Demo "),(0,o.kt)("p",null,"\ud83d\udd35 require "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\ud83d\udd36 ubuntu 20\n\n\u203c\ufe0f \ud83d\udd25 NO Docker installed! Docker has buildin xxx. but we need CRI-O \u203c\ufe0f\n\u203c\ufe0f \ud83d\udd25 NO Docker installed! Docker has buildin xxx. but we need CRI-O \u203c\ufe0f\n\u203c\ufe0f \ud83d\udd25 NO Docker installed! Docker has buildin xxx. but we need CRI-O \u203c\ufe0f\n\n\n    \ud83d\udd36 uninstall old docker \n\n        $ sudo apt-get purge -y docker-engine docker docker.io docker-ce  \n        $ sudo apt-get autoremove -y --purge docker-engine docker docker.io docker-ce  \n\n\n\u203c\ufe0f \ud83d\udd25 at least two node.  or  k8s dashboard no work. \u203c\ufe0f\n\n\nram must 2G + .  most vps no....\n")),(0,o.kt)("p",null,"\ud83d\udd35 VM Prepair"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\ud83d\udd36 set Hostname & static IP   ???\n\n    K8s-Manager       172.16.0.80\n    K8s-WorkerG3      172.16.0.83\n\n\n        hostnamectl set-hostname your-new-hostname\n        hostnamectl set-hostname K8s-Worker-VPS\n\n        client only need add manager`s hostname?\n        what if some nodes not in same vlan.\n")),(0,o.kt)("p",null,"\ud83d\udd35 Disable swap - All Node "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"https://graspingtech.com/disable-swap-ubuntu/\n\n\n\ud83d\udd36 Check \n\n    sudo swapon --show\n    if nothing it is disabled.\n\n\n\ud83d\udd36 forever turn off swap \n\n   sudo vi /etc/fstab\n        remove /swap line \n            /swap.img       none    swap    sw      0       0\n")),(0,o.kt)("p",null,"\ud83d\udd35 Config firewall "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\ud83d\udd36 like this is ok.\n\n    [root@localhost ~]# lsmod |grep br_netfilter\n    br_netfilter           22209  0\n    bridge                136173  1 br_netfilter\n")),(0,o.kt)("p",null,"\ud83d\udd35 Install CRI-O - ALL Node  \u2705"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    \u203c\ufe0f if you have docker/contained install already. something will wrong. \u203c\ufe0f\n        use a new system. No install docker/contained! \n\n\n\ud83d\udd36 Set OS & CRI-o version value\n\n    K8s-Mgr.Root ~ OS=xUbuntu_20.04\n    K8s-Mgr.Root ~ VERSION=1.24\n        \ud83d\udd25 must run this.   set system version\n        \u25ce find your system\n            https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/\n\n        \u25ce check lsteat cri-o version \n            https://github.com/cri-o/cri-o\n                should be same version with k8s.\n\n\n\ud83d\udd36 Copy & Paste \n        \n    # Add Kubic Repo\n    echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /" | \\\n    sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list\n\n    # Import Public Key\n    curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/Release.key | \\\n    sudo apt-key add -\n\n    # Add CRI Repo\n    echo "deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/$VERSION/$OS/ /" | \\\n    sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list\n\n    # Import Public Key\n    curl -L https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:$VERSION/$OS/Release.key | \\\n    sudo apt-key add -\n\n\n\ud83d\udd36 Install \n\n    sudo apt update\n    sudo apt install cri-o cri-o-runc cri-tools -y\n\n\n\ud83d\udd36 enable\n\n    sudo systemctl enable crio.service\n\n\n\ud83d\udd36 start & check \n\n    sudo systemctl start crio.service\n    sudo crictl info\n        \u203c\ufe0f make sure runtime is ready.  network ignore it. \u203c\ufe0f\n')),(0,o.kt)("p",null,"\ud83d\udd35 Kubernetes tooles install - ALl Node \u2705"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'\ud83d\udd36 Tooles Desc \n\n    \u25ce kubeadm:    Deploy k8s cluster\n    \u25ce kubelet:    manager pod/network \n    \u25ce kubectl:    k8s cli tool.\n\n\n\ud83d\udd36  add key \n\n    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add\n\n\n\ud83d\udd36 add apt repository \n\n    echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" >> ~/kubernetes.list\n    sudo mv ~/kubernetes.list /etc/apt/sources.list.d\n\n\n\ud83d\udd36 Install  tooles \n\n    sudo apt-get update\n\n    sudo apt-get install -y kubelet kubeadm kubectl\n\n    sudo apt-mark hold kubelet kubeadm kubectl  \n        apt-mark means no update these package when you update your system!\n        update package often cause problems.\n        \n')),(0,o.kt)("p",null,"\ud83d\udd35 Create Cluster (Mgr node) \u2705"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\ud83d\udd36 Create \n\n    sudo kubeadm init --pod-network-cidr=10.244.0.0/16\n\n        kubeadm join 172.16.0.80:6443 --token qrtig7v35 \\\n            --discovery-token-ca-cert-hash sha256:d6\n")),(0,o.kt)("p",null,"\ud83d\udd35 check join cmd "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"if forget join cmd. \ncheck \n")),(0,o.kt)("p",null,"kubeadm token create --print-join-command"),(0,o.kt)("p",null,"kubeadm join 172.16.0.80:6443 --token oi0nrh.ns09no --discovery-token-ca-cert-hash sha256:7"),(0,o.kt)("p",null,"\ud83d\udd35 Worker join cluster."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubeadm join 172.16.0.80:6443 --token qrti3b.3tg7v35 \\\n                --discovery-token-ca-cert-hash sha256:f83007a\n\n\n\ud83d\udd36 ? \n")),(0,o.kt)("p",null,"\ud83d\udd35 Reset K8s Cluster - option "),(0,o.kt)("p",null,"  ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset/"},"https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset/"),"\n",(0,o.kt)("a",{parentName:"p",href:"https://www.techrunnr.com/how-to-reset-kubernetes-cluster/"},"https://www.techrunnr.com/how-to-reset-kubernetes-cluster/")),(0,o.kt)("p",null,"  kubeadm reset -f\n\u203c\ufe0f All node need reset. \u203c\ufe0f"),(0,o.kt)("p",null,"\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35 Manager config dashboard\n\ud83d\udd36"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"mkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n")),(0,o.kt)("p",null,"\ud83d\udd36 firewall "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"sudo ufw allow 6443\nsudo ufw allow 6443/tcp\n")),(0,o.kt)("p",null,"\ud83d\udd35 flannel plugin "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\ud83d\udd36 function \n\n    manage docker network \n    like subnet. \n\n\n\ud83d\udd36 Install\n\n    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/k8s-manifests/kube-flannel-rbac.yml\n\n\n\ud83d\udd36 check status\n\n    kubectl get pods --all-namespaces\n    kubectl get componentstatus\n    kubectl get cs\n")),(0,o.kt)("p",null,"\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35 K8s Dashboard "),(0,o.kt)("p",null,"\ud83d\udd35 K8s dashboard "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"https://github.com/kubernetes/dashboard\n\n\nhttps://github.com/kubernetes/dashboard/releases\n")),(0,o.kt)("p",null,"\ud83d\udd36 install "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.6.0/aio/deploy/recommended.yaml\n\n\n\u25ce delete/remove - option\n    kubectl delete -f xxxx\n")),(0,o.kt)("p",null,"\ud83d\udd36 Check dashboard stauts"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubectl get pods --all-namespaces\n    make sure  kubernetes-dashboard is running .  not pendding ..\n\n        if not running check name spcae log\n            kubectl get events -n <namespace> \n            kubectl get events -n kubernetes-dashboard\n")),(0,o.kt)("p",null,"\ud83d\udd36 Dashboard Login Desc "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"by default. \nonly allow local machine (k8s manager node) to login.\n\nwe need login dashboard from remote machine.\n")),(0,o.kt)("p",null,"\ud83d\udd36 Dashboard \u25aa Change  type "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubectl -n kubernetes-dashboard edit service kubernetes-dashboard\n\n    k8s-app: kubernetes-dashboard\n    sessionAffinity: None\n    type: NodePort   \u279c change  from clusterip to nodeport \n")),(0,o.kt)("p",null,"\ud83d\udd36 Dashboard \u25aa get web port (443:30484)"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"K8s-Manager ~ kubectl get svc -n kubernetes-dashboard\nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\ndashboard-metrics-scraper   ClusterIP   10.102.194.58   <none>        8000/TCP        4m41s\nkubernetes-dashboard        NodePort    10.97.178.197   <none>        443:xxxxx/TCP   4m41s\n")),(0,o.kt)("p",null,"\ud83d\udd36Dashboard \u25aa Log in "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"https://172.16.0.80:xxxxx/\nhttps://172.16.0.80:30775\n\nneed token.\nwe need create user first.  \nthen create token for that user\nthen can back.\n")),(0,o.kt)("p",null,"\ud83d\udd35 Create Dashboard user "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"create two yaml file:  xxx.yaml\nuse kubectl apply -f xxx.yaml to apply.\n")),(0,o.kt)("p",null,"\ud83d\udd36 File_01:   miranda.yaml"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"sudo bash -c 'echo \"\napiVersion: v1\nkind: ServiceAccount\nmetadata:\nname: miranda\nnamespace: kubernetes-dashboard\n\" > /root/miranda.yaml'\n")),(0,o.kt)("p",null,"\ud83d\udd36 File_02:  ClusterRoleBinding.yaml"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"sudo bash -c 'echo \"\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\nname: miranda\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\nsubjects:\n- kind: ServiceAccount\nname: miranda\nnamespace: kubernetes-dashboard\n\" > /root/ClusterRoleBinding.yaml'\n")),(0,o.kt)("p",null,"\ud83d\udd36 apply yaml"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubectl apply -f miranda.yaml\nkubectl apply -f ClusterRoleBinding.yaml\n\n    \u25ce delete yaml (option )\n        kubectl delete -f  miranda.yaml\n")),(0,o.kt)("p",null,"\ud83d\udd36 get user token & login "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubectl -n kubernetes-dashboard create token miranda\n\ncpoy token to website. \nso we can login. now.\n")))}p.isMDXComponent=!0}}]);